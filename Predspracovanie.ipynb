{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1677,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_csv('data-set/personal_valid.csv')\n",
    "dfo = pd.read_csv('data-set/other_valid.csv')\n",
    "dfp = dfp.rename(columns={'Unnamed: 0': 'ID'})\n",
    "dfo = dfo.rename(columns={'Unnamed: 0': 'ID'})\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrácia dát a deduplikácia záznamov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táto časť je skopírovaná z predchadzajúceho notebooku 'Prieskumná_analýza.ipynb'. Spojí dataset other a personal do jedného a následne odstráni duplikatne záznamy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges duplicates\n",
    "def merge(name):\n",
    "    df = dfo_duplicates.loc[dfo_duplicates['name'] == name]\n",
    "    return df.groupby(['name'], as_index=False).first()\n",
    "\n",
    "def merge_other_personal(df):\n",
    "    dfo_duplicates = dfo[dfo.duplicated(['name'], keep=False)]\n",
    "    dfo_unique = dfo.drop_duplicates(subset=[\"name\"], keep=False)\n",
    "    merged = []\n",
    "\n",
    "    for name in dfo_duplicates['name'].unique():\n",
    "        merged.append(merge(name))\n",
    "\n",
    "    dfo_unique = dfo_unique.append(merged)\n",
    "\n",
    "    x = pd.merge(dfp, dfo_unique, on='name')\n",
    "    x = x.drop(columns=['address_y', 'ID_y'])\n",
    "    x = x.rename(columns={\"ID_x\": \"ID\", \"address_x\": \"address\"})\n",
    "    return x\n",
    "    \n",
    "# df = merge_other_personal(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalsia vec ktoru musime spravit, je rozbalenie medical info. Nachadza sa tu: kurtosis_oxygen, mean_oxygen, skewness_oxygen a std_oxygen. Tieto hodnoty su ulozene ako object (string), pre to ich budeme musiet previest na cislo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_medical(df):\n",
    "    x = df.copy()\n",
    "    for i, row in x.iterrows():\n",
    "        if not pd.isnull(x.at[i, 'medical_info']):\n",
    "            x.at[i, 'medical_info'] = json.loads(x[\"medical_info\"][i].replace(\"\\'\", \"\\\"\"))\n",
    "    # vytvorenie stlpcov z medical_info a ich spojenie so zvyskom dataframe\n",
    "    df_med_info = x[\"medical_info\"].apply(pd.Series)\n",
    "    df_med_info = df_med_info.drop(0, 1)\n",
    "    x = pd.concat([x, df_med_info], axis = 1).drop(\"medical_info\", axis = 1)\n",
    "    return x\n",
    "\n",
    "# df = unpack_medical(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmena kurtosis_oxygen, mean_oxygen, skewness_oxygen, std_oxygen z object na float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_to_float(df):\n",
    "    x = df.copy()\n",
    "    # kurtosis_oxygen\n",
    "    x['kurtosis_oxygen'] = x['kurtosis_oxygen'].astype(np.float)\n",
    "    # mean_oxygen\n",
    "    x['mean_oxygen'] = x['mean_oxygen'].astype(np.float)\n",
    "    # skewness_oxygen\n",
    "    x['skewness_oxygen'] = x['skewness_oxygen'].astype(np.float)\n",
    "    # std_oxygen\n",
    "    x['std_oxygen'] = x['std_oxygen'].astype(np.float)\n",
    "    return x\n",
    "# df = obj_to_float(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozhodli sme sa dropnut niektore stlpce. Meno, ID, fnlwgt. Dovodom je, ze kazda z tychto hodnot je rozna a na vyskyt cukrovky nema vplyv.  \n",
    "Mame 2 udaje ktore nam ukazuju vek cloveka - age a date_of_birth. Kedze nemame ziadne nullove hodnoty pri age, nemusime podla datumu narodenia vek urcovat. Datum narodenia teda mozeme vyhodit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1664,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unimportant_columns(df):\n",
    "    x = df.copy()\n",
    "    x = x.drop(['ID', 'name', 'fnlwgt', 'date_of_birth'], axis=1)\n",
    "    return x\n",
    "# df = remove_unimportant_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odstranenie space-ov z nazvov atributov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1665,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(df):\n",
    "    x = df.copy()\n",
    "    x = df.apply(lambda y: y.str.strip() if y.dtype == \"object\" else y)\n",
    "    return x\n",
    "\n",
    "# df = remove_space(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nahradenie hodnot, ktore mozu nadobudat len 2 stavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_0_1_values(df):\n",
    "    x = df.copy()\n",
    "    \n",
    "    # pohlavia: Male -> 1; Female -> 0\n",
    "    x['sex'] = x['sex'].replace('Male', 1)\n",
    "    x['sex'] = x['sex'].replace('Female', 0)\n",
    "    \n",
    "    # tehotnost: T -> 1; F -> 0\n",
    "    x['pregnant'] = x['pregnant'].replace(regex='(?i)f.*', value=0)\n",
    "    x['pregnant'] = x['pregnant'].replace(regex='(?i)t.*', value=1)\n",
    "    \n",
    "    # muzi oznaceni ako tehotny su prepisani na 0\n",
    "    x.loc[(x['pregnant'] == 1) & (x['sex'] == 1), 'pregnant'] = 0\n",
    "    \n",
    "    # zmena income hodnot: <=50K -> 0; >50K -> 1\n",
    "    x['income'] = x['income'].replace('<=50K', 0)\n",
    "    x['income'] = x['income'].replace('>50K', 1)\n",
    "    \n",
    "    # zmena nazvov stlpcov na presnejsie\n",
    "    x = x.rename(columns={\"pregnant\": \"is_pregnant\", \"income\": \"income_>50K\"})\n",
    "    \n",
    "    return x\n",
    "\n",
    "# df = put_0_1_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Education a education-num**  \n",
    "Zistujeme, co znamena education a education num. Predpoklad je, ze education-num je numericka reprezentacia education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def education_analysis(df):\n",
    "    # prints unique values in education\n",
    "    x = df.copy()\n",
    "    unique_edu = pd.unique(x['education'])\n",
    "    print(\"Pred zjednotenim:\\n\", unique_edu)\n",
    "    \n",
    "    # Zjednotenie reprezentacii\n",
    "    x['education'] = x['education'].replace(regex='(?i)_', value='-')\n",
    "    unique_edu = pd.unique(x['education'])\n",
    "    print(\"\\nPo zjednoteni:\\n\", unique_edu)\n",
    "    \n",
    "    # hodnoty v education-num a v education\n",
    "    print(\"\\nHodnoty v jednotlivych education:\")\n",
    "    for item in unique_edu:\n",
    "        edu_num = x.query(\"education == @item\")[\"education-num\"].unique()\n",
    "        print(item, edu_num)\n",
    "\n",
    "# education_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidime ze education-num je ciselna reprezentacia education. Vytvorime si dictionary, ktory bude priradovat education ku education-num, s tym ze nechame celociselne reprezentacie od 1 po 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vrati unikatne hodnoty v stlpci education\n",
    "def get_unique_edu(df):\n",
    "    x = df.copy()\n",
    "    x['education'] = x['education'].replace(regex='(?i)_', value='-')\n",
    "    unique_edu = pd.unique(x['education'])\n",
    "    return unique_edu\n",
    "\n",
    "# rozne hodnoty education-num pre unikatny education zmeni na jedno (napr.: 5th-6th [  3. 300.] -> 3)\n",
    "def get_edu_num(edu_num):\n",
    "    for num in edu_num:\n",
    "        if num is None:\n",
    "            continue\n",
    "        elif num < 100:\n",
    "            return int(num)\n",
    "\n",
    "def transform_education(df):\n",
    "    x = df.copy()\n",
    "    edu_to_num = {}\n",
    "    #vytvorenie dictionary s moznymi hodnotami v jendotlivych education values\n",
    "    for item in get_unique_edu(x):\n",
    "        edu_num = x.query(\"education == @item\")[\"education-num\"].unique()\n",
    "        edu_to_num[item] = get_edu_num(edu_num)\n",
    "    \n",
    "    # zmena moznych hodnot v education na rovnake\n",
    "    x['education'] = x['education'].replace(regex='(?i)_', value='-')\n",
    "\n",
    "    # namapuje nazvy education na cisla z dictionary\n",
    "    x[\"education\"] = x[\"education\"].map(edu_to_num)\n",
    "    \n",
    "    # Dropne nepotrebny column education-num (bol nahradeny)\n",
    "    x = x.drop(['education-num'], axis=1)\n",
    "    return x\n",
    "    \n",
    "# df = transform_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cele adresy nam netreba pretoze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_state(address):\n",
    "    i = re.search('\\x5cn.+\\D', address)\n",
    "    return address[i.start():i.end()][-3:-1]\n",
    "    #return address[-8:][:2]\n",
    "\n",
    "def address_to_state(df):\n",
    "    x = df.copy()\n",
    "    x['address'] = x['address'].apply(find_state)\n",
    "    x = x.rename(columns={\"address\": \"state\"})\n",
    "    return x\n",
    "\n",
    "# df = address_to_state(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otazniky zmenime na NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_nan(df):\n",
    "    x = df.copy()\n",
    "    x = x.replace(['??', '?'], np.nan)\n",
    "    return x\n",
    "# df = replace_with_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zjednotime hodnoty vo workclass (local-gov a Local-gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_workclass(df):\n",
    "    x = df.copy()\n",
    "    x['workclass'] = x['workclass'].str.lower()\n",
    "    return x\n",
    "# df = transform_workclass(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia spajajuca integraciu dat do jednej. Integraciu tvori spojenie dataframov other a personal, deduplikacia zaznamov, zjednotenie interpretacii hodnot a zbavenie sa nepotrebnych stlpcov, pripadne ponechanie casti hodnoty v stlpci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration_combined(df):\n",
    "    x = df.copy()\n",
    "    # merges other and personal df\n",
    "    x = merge_other_personal(x)\n",
    "    # upacks medical info into columns\n",
    "    x = unpack_medical(x)\n",
    "    # changes objects unpacked in medical info (oxygen) to float\n",
    "    x = obj_to_float(x)\n",
    "\n",
    "    # remove unimportant columns like name or fnlwgt\n",
    "    x = remove_unimportant_columns(x)\n",
    "    # removes spaces at the start of values\n",
    "    x = remove_space(x)\n",
    "    # replace values that have only 2 options vwith 1 or 2\n",
    "    x = put_0_1_values(x)\n",
    "    # gets rid of education and replaces it with number from education-num\n",
    "    x = transform_education(x)\n",
    "    # gets rid of address and only keep state\n",
    "    x = address_to_state(x)\n",
    "    # replaces ? with nan\n",
    "    x = replace_with_nan(x)\n",
    "    # workclass values into lower case -> gets rid of duplicates\n",
    "    x = transform_workclass(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmena na ciselne hodnoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- race ---\n",
      "4 : White\n",
      "2 : Black\n",
      "1 : Asian-Pac-Islander\n",
      "3 : Other\n",
      "0 : Amer-Indian-Eskimo\n",
      "\n",
      "\n",
      "--- state ---\n",
      "13 : GA\n",
      "19 : KS\n",
      "1 : AE\n",
      "4 : AP\n",
      "29 : MT\n",
      "22 : MA\n",
      "0 : AA\n",
      "24 : ME\n",
      "48 : VA\n",
      "16 : ID\n",
      "43 : SC\n",
      "15 : IA\n",
      "26 : MN\n",
      "39 : OK\n",
      "42 : RI\n",
      "33 : NH\n",
      "9 : CT\n",
      "40 : OR\n",
      "11 : DE\n",
      "27 : MO\n",
      "25 : MI\n",
      "51 : WI\n",
      "50 : WA\n",
      "53 : WY\n",
      "30 : NC\n",
      "52 : WV\n",
      "37 : NY\n",
      "7 : CA\n",
      "45 : TN\n",
      "6 : AZ\n",
      "35 : NM\n",
      "46 : TX\n",
      "2 : AK\n",
      "34 : NJ\n",
      "5 : AR\n",
      "20 : KY\n",
      "41 : PA\n",
      "17 : IL\n",
      "32 : NE\n",
      "36 : NV\n",
      "28 : MS\n",
      "44 : SD\n",
      "14 : HI\n",
      "12 : FL\n",
      "38 : OH\n",
      "49 : VT\n",
      "8 : CO\n",
      "47 : UT\n",
      "21 : LA\n",
      "23 : MD\n",
      "3 : AL\n",
      "18 : IN\n",
      "10 : DC\n",
      "31 : ND\n",
      "\n",
      "\n",
      "--- marital-status ---\n",
      "2 : Married-civ-spouse\n",
      "0 : Divorced\n",
      "6 : Widowed\n",
      "4 : Never-married\n",
      "5 : Separated\n",
      "3 : Married-spouse-absent\n",
      "1 : Married-AF-spouse\n",
      "\n",
      "\n",
      "--- occupation ---\n",
      "6 : Other-service\n",
      "5 : Machine-op-inspct\n",
      "8 : Prof-specialty\n",
      "4 : Handlers-cleaners\n",
      "10 : Sales\n",
      "1 : Craft-repair\n",
      "0 : Adm-clerical\n",
      "2 : Exec-managerial\n",
      "11 : Tech-support\n",
      "3 : Farming-fishing\n",
      "12 : Transport-moving\n",
      "7 : Priv-house-serv\n",
      "9 : Protective-serv\n",
      "\n",
      "\n",
      "--- relationship ---\n",
      "0 : Husband\n",
      "3 : Own-child\n",
      "4 : Unmarried\n",
      "1 : Not-in-family\n",
      "2 : Other-relative\n",
      "5 : Wife\n",
      "\n",
      "\n",
      "--- native-country ---\n",
      "27 : United-States\n",
      "1 : Canada\n",
      "21 : Poland\n",
      "29 : Yugoslavia\n",
      "12 : Iran\n",
      "11 : India\n",
      "16 : Japan\n",
      "23 : Puerto-Rico\n",
      "17 : Mexico\n",
      "6 : El-Salvador\n",
      "5 : Dominican-Republic\n",
      "8 : Germany\n",
      "4 : Cuba\n",
      "9 : Guatemala\n",
      "20 : Philippines\n",
      "24 : Taiwan\n",
      "7 : England\n",
      "26 : Trinadad&Tobago\n",
      "10 : Hungary\n",
      "2 : China\n",
      "15 : Jamaica\n",
      "19 : Peru\n",
      "0 : Cambodia\n",
      "14 : Italy\n",
      "18 : Outlying-US(Guam-USVI-etc)\n",
      "3 : Columbia\n",
      "25 : Thailand\n",
      "28 : Vietnam\n",
      "13 : Ireland\n",
      "22 : Portugal\n",
      "\n",
      "\n",
      "--- workclass ---\n",
      "2 : private\n",
      "1 : local-gov\n",
      "4 : self-emp-not-inc\n",
      "5 : state-gov\n",
      "0 : federal-gov\n",
      "3 : self-emp-inc\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>race</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>native-country</th>\n",
       "      <th>workclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>is_pregnant</th>\n",
       "      <th>skewness_glucose</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>kurtosis_glucose</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>std_glucose</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>kurtosis_oxygen</th>\n",
       "      <th>mean_oxygen</th>\n",
       "      <th>skewness_oxygen</th>\n",
       "      <th>std_oxygen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400023</td>\n",
       "      <td>113.687500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038520</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.326894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.642782</td>\n",
       "      <td>7.227425</td>\n",
       "      <td>21.804034</td>\n",
       "      <td>31.430288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.250361</td>\n",
       "      <td>34.406250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.243557</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.877558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.731936</td>\n",
       "      <td>41.427258</td>\n",
       "      <td>2.537562</td>\n",
       "      <td>61.235473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377293</td>\n",
       "      <td>101.328125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374884</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.385465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.134172</td>\n",
       "      <td>3.418896</td>\n",
       "      <td>58.953559</td>\n",
       "      <td>19.263642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.459422</td>\n",
       "      <td>9.976562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.859134</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.258590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.742921</td>\n",
       "      <td>68.934783</td>\n",
       "      <td>-0.089009</td>\n",
       "      <td>65.174611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.243264</td>\n",
       "      <td>134.835938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.299902</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.723635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.078860</td>\n",
       "      <td>2.269231</td>\n",
       "      <td>89.748456</td>\n",
       "      <td>18.351895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.611897</td>\n",
       "      <td>85.828125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783824</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.656589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.701320</td>\n",
       "      <td>3.136288</td>\n",
       "      <td>73.019918</td>\n",
       "      <td>17.460629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.021146</td>\n",
       "      <td>35.929688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.326209</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.317723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.669580</td>\n",
       "      <td>22.634615</td>\n",
       "      <td>6.700531</td>\n",
       "      <td>50.468320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.515704</td>\n",
       "      <td>125.968750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106988</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.607130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.371372</td>\n",
       "      <td>2.594482</td>\n",
       "      <td>104.136934</td>\n",
       "      <td>16.903779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303495</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.399098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.559185</td>\n",
       "      <td>6.393813</td>\n",
       "      <td>30.623632</td>\n",
       "      <td>33.970594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691393</td>\n",
       "      <td>151.781250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.124521</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.850747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.687270</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>196.380946</td>\n",
       "      <td>12.493713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1311 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  race  marital-status  occupation  relationship  native-country  \\\n",
       "0        13     4               2           6             0              27   \n",
       "1        19     4               0           5             3              27   \n",
       "2         1     2               6           5             4              27   \n",
       "3         4     4               4           8             1              27   \n",
       "4        29     4               2           4             0              27   \n",
       "...     ...   ...             ...         ...           ...             ...   \n",
       "1306      3     4               0           8             4              27   \n",
       "1307     45     4               4           4             3              22   \n",
       "1308     42     4               2          10             0              27   \n",
       "1309     21     4               4           1             3              27   \n",
       "1310     27     4               2           8             5              27   \n",
       "\n",
       "      workclass   age  sex  is_pregnant  skewness_glucose  mean_glucose  \\\n",
       "0             2  48.0  1.0          0.0          0.400023    113.687500   \n",
       "1             2  54.0  0.0          0.0         31.250361     34.406250   \n",
       "2             2  48.0  0.0          0.0          0.377293    101.328125   \n",
       "3             2  59.0  0.0          0.0         35.459422      9.976562   \n",
       "4             2  36.0  1.0          0.0         -0.243264    134.835938   \n",
       "...         ...   ...  ...          ...               ...           ...   \n",
       "1306          1  46.0  0.0          0.0          2.611897     85.828125   \n",
       "1307          2  53.0  1.0          0.0         34.021146     35.929688   \n",
       "1308          2  33.0  1.0          0.0         -0.515704    125.968750   \n",
       "1309          2  55.0  1.0          0.0          0.303495    127.250000   \n",
       "1310          1  53.0  0.0          0.0          0.691393    151.781250   \n",
       "\n",
       "      capital-gain  kurtosis_glucose  education  class  std_glucose  \\\n",
       "0              0.0          0.038520       11.0    0.0    45.326894   \n",
       "1              0.0          5.243557       10.0    1.0    31.877558   \n",
       "2              0.0          0.374884       10.0    0.0    43.385465   \n",
       "3              0.0          5.859134       11.0    1.0    32.258590   \n",
       "4              0.0         -0.299902        9.0    0.0    50.723635   \n",
       "...            ...               ...        ...    ...          ...   \n",
       "1306           0.0          0.783824       13.0    0.0    35.656589   \n",
       "1307           0.0          5.326209        9.0    1.0    31.317723   \n",
       "1308           0.0          0.106988        9.0    0.0    51.607130   \n",
       "1309           0.0          0.111974        7.0    1.0    45.399098   \n",
       "1310           0.0         -0.124521       14.0    0.0    42.850747   \n",
       "\n",
       "      income_>50K  hours-per-week  capital-loss  kurtosis_oxygen  mean_oxygen  \\\n",
       "0             0.0            40.0           0.0         4.642782     7.227425   \n",
       "1             0.0            40.0           0.0         1.731936    41.427258   \n",
       "2             0.0            48.0           0.0         7.134172     3.418896   \n",
       "3             1.0            40.0        1564.0         0.742921    68.934783   \n",
       "4             1.0            40.0           0.0         9.078860     2.269231   \n",
       "...           ...             ...           ...              ...          ...   \n",
       "1306          0.0            35.0           0.0         7.701320     3.136288   \n",
       "1307          0.0            50.0           0.0         2.669580    22.634615   \n",
       "1308          1.0            40.0           0.0         9.371372     2.594482   \n",
       "1309          0.0            30.0           0.0         5.559185     6.393813   \n",
       "1310          1.0            40.0           0.0        12.687270     1.384615   \n",
       "\n",
       "      skewness_oxygen  std_oxygen  \n",
       "0           21.804034   31.430288  \n",
       "1            2.537562   61.235473  \n",
       "2           58.953559   19.263642  \n",
       "3           -0.089009   65.174611  \n",
       "4           89.748456   18.351895  \n",
       "...               ...         ...  \n",
       "1306        73.019918   17.460629  \n",
       "1307         6.700531   50.468320  \n",
       "1308       104.136934   16.903779  \n",
       "1309        30.623632   33.970594  \n",
       "1310       196.380946   12.493713  \n",
       "\n",
       "[1311 rows x 24 columns]"
      ]
     },
     "execution_count": 1749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_encode_strings(df):\n",
    "    \"\"\"Nahradi stringy ciselnymi hodnotami pomocou sklearn LabelEncoderu.\"\"\"\n",
    "    x = df.copy()\n",
    "    \n",
    "    enc = LabelEncoder()\n",
    "    cols_to_transform = ['race', 'state', 'marital-status', 'occupation', 'relationship', 'native-country', 'workclass']\n",
    "    x[cols_to_transform] = x[cols_to_transform].apply(enc.fit_transform)\n",
    "    \n",
    "    for i in cols_to_transform:\n",
    "        print(f'--- {i} ---')\n",
    "        values = df[i].unique()\n",
    "        encoded = enc.fit(values).transform(values)\n",
    "        encoding = enc.inverse_transform(encoded)\n",
    "        for e in range(len(encoded)):\n",
    "            print(f'{encoded[e]} : {encoding[e]}')\n",
    "        print('\\n')\n",
    "    \n",
    "    return x\n",
    "label_encode_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chybajuce hodnoty a outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chybajuce hodnoty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chybajuce hodnoty doplname osobitne pre ciselne udaje a osobitne pre kategoricke udaje. Na numericke pouzivame metody median, mean a KNN. Vyber ktoru pouzijeme sa zadava v pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_dtype(df):\n",
    "    \"\"\"Rozdeli dataframe na stringy a numericke data.\"\"\"\n",
    "    df_num = pd.DataFrame()\n",
    "    df_str = pd.DataFrame()\n",
    "\n",
    "    for col in df:\n",
    "        # Ak je to int alebo float tak sa jedna o numericke data\n",
    "        if df[col].dtypes in ['float64', 'int64']:\n",
    "            df_num[col] = df[col]\n",
    "        else: # Inak string\n",
    "            df_str[col] = df[col]\n",
    "    \n",
    "    return df_num, df_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_strings(df):\n",
    "        \"\"\"Nahradi chybajuce stringy pomocou SimpleImputer zo sklearn.impute strategiou most_frequent.\"\"\"\n",
    "        x = df.copy()\n",
    "        x = SimpleImputer(strategy=\"most_frequent\").fit_transform(x)\n",
    "        \n",
    "        # Z novych hodnot sa vytvori dataframe\n",
    "        x = pd.DataFrame(x)\n",
    "        \n",
    "        # Pomenujeme stlpce a riadky rovnako ako v povodnom dataframe\n",
    "        x.columns = df.columns\n",
    "        x.index = df.index\n",
    "        \n",
    "        return x\n",
    "\n",
    "def replace_missing_numbers(df, strat='median'):\n",
    "    \"\"\"Nahradi chybajuce numericke data pomocou zvolenej strategie (median, mean alebo kNN).\"\"\"\n",
    "    x = df.copy()\n",
    "    \n",
    "    # Pre zvolenu strategiu sa vytvori imputer\n",
    "    if strat in ['mean', 'median']:\n",
    "        imp = SimpleImputer(strategy=strat)\n",
    "    else:\n",
    "        imp = KNNImputer()\n",
    "    \n",
    "    # Doplnia sa chybajuce hodnoty\n",
    "    x = imp.fit_transform(x)\n",
    "    \n",
    "    # Z novych hodnot sa vytvori dataframe\n",
    "    x = pd.DataFrame(x)\n",
    "    \n",
    "    # Pomenujeme stlpce a riadky rovnako ako v povodnom dataframe\n",
    "    x.columns = df.columns\n",
    "    x.index = df.index\n",
    "    \n",
    "    x['class'] = x['class'].round()\n",
    "    x['income_>50K'] = x['income_>50K'].round()\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1675,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(df, strat='median'):\n",
    "    df_num, df_str = separate_by_dtype(df)\n",
    "    \n",
    "    df_str = replace_missing_strings(df_str)\n",
    "    df_num = replace_missing_numbers(df_num, strat)\n",
    "    \n",
    "    return pd.concat([df_str, df_num], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Znovupoužiteľnosť predspracovania - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1311 entries, 0 to 1310\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   state             1311 non-null   object \n",
      " 1   race              1311 non-null   object \n",
      " 2   marital-status    1311 non-null   object \n",
      " 3   occupation        1311 non-null   object \n",
      " 4   relationship      1311 non-null   object \n",
      " 5   native-country    1311 non-null   object \n",
      " 6   workclass         1311 non-null   object \n",
      " 7   age               1311 non-null   float64\n",
      " 8   sex               1311 non-null   float64\n",
      " 9   is_pregnant       1311 non-null   float64\n",
      " 10  skewness_glucose  1311 non-null   float64\n",
      " 11  mean_glucose      1311 non-null   float64\n",
      " 12  capital-gain      1311 non-null   float64\n",
      " 13  kurtosis_glucose  1311 non-null   float64\n",
      " 14  education         1311 non-null   float64\n",
      " 15  class             1311 non-null   float64\n",
      " 16  std_glucose       1311 non-null   float64\n",
      " 17  income_>50K       1311 non-null   float64\n",
      " 18  hours-per-week    1311 non-null   float64\n",
      " 19  capital-loss      1311 non-null   float64\n",
      " 20  kurtosis_oxygen   1311 non-null   float64\n",
      " 21  mean_oxygen       1311 non-null   float64\n",
      " 22  skewness_oxygen   1311 non-null   float64\n",
      " 23  std_oxygen        1311 non-null   float64\n",
      "dtypes: float64(17), object(7)\n",
      "memory usage: 296.1+ KB\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('integration', FunctionTransformer(func=integration_combined)),\n",
    "    ('replace_nan', FunctionTransformer(func=replace_missing_values, kw_args={'strat': 'median'}))\n",
    "])\n",
    "df = pipeline.fit_transform(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opätovná realizácia podstatných častí prieskumnej analýzy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
