{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import preprocessing_functions as ps\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_csv('data-set/personal_train.csv')\n",
    "dfo = pd.read_csv('data-set/other_train.csv')\n",
    "dfp = dfp.rename(columns={'Unnamed: 0': 'ID'})\n",
    "dfo = dfo.rename(columns={'Unnamed: 0': 'ID'})\n",
    "pd.set_option('display.max_columns', 30)\n",
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vypise ci mame niejake duplikaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal: 0\n",
      "Other: 99\n"
     ]
    }
   ],
   "source": [
    "print(f\"Personal: {len(dfp[dfp.duplicated(['name'], keep=False)])}\")\n",
    "dfo_duplicates = dfo[dfo.duplicated(['name'], keep=False)]\n",
    "print(f\"Other: {len(dfo_duplicates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zistime ci ich vieme mergnut rovnako ako pri prvom datasete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.mergeable(dfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns true if we can merge duplicates -> there are no conflicts\n",
    "def mergeable(dfo):\n",
    "    dfo_duplicates = dfo[dfo.duplicated(['name'], keep=False)]\n",
    "    unique_names = dfo_duplicates['name'].unique()\n",
    "    for name in unique_names:\n",
    "        duplicates = dfo_duplicates.loc[dfo_duplicates['name'] == name]\n",
    "        for col in duplicates.columns:\n",
    "            if col == 'ID':\n",
    "                continue\n",
    "            values = duplicates[col].unique()\n",
    "            if len(values) > 2:\n",
    "                return False\n",
    "            elif len(values) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                if pd.isnull(values[0]) or pd.isnull(values[1]):\n",
    "                    continue\n",
    "    return True\n",
    "\n",
    "\n",
    "# merges duplicates\n",
    "def merge(name, dfo_duplicates):\n",
    "    df = dfo_duplicates.loc[dfo_duplicates['name'] == name]\n",
    "    return df.groupby(['name'], as_index=False).first()\n",
    "\n",
    "\n",
    "def merge_other_personal(df):\n",
    "    dfo_duplicates = dfo[dfo.duplicated(['name'], keep=False)]\n",
    "    dfo_unique = dfo.drop_duplicates(subset=[\"name\"], keep=False)\n",
    "    merged = []\n",
    "\n",
    "    for name in dfo_duplicates['name'].unique():\n",
    "        merged.append(merge(name, dfo_duplicates))\n",
    "\n",
    "    dfo_unique = dfo_unique.append(merged)\n",
    "\n",
    "    x = pd.merge(dfp, dfo_unique, on='name')\n",
    "    x = x.drop(columns=['address_y', 'ID_y'])\n",
    "    x = x.rename(columns={\"ID_x\": \"ID\", \"address_x\": \"address\"})\n",
    "    return x\n",
    "\n",
    "def unpack_medical(df):\n",
    "    x = df.copy()\n",
    "    for i, row in x.iterrows():\n",
    "        if not pd.isnull(x.at[i, 'medical_info']):\n",
    "            x.at[i, 'medical_info'] = json.loads(x[\"medical_info\"][i].replace(\"\\'\", \"\\\"\"))\n",
    "    # vytvorenie stlpcov z medical_info a ich spojenie so zvyskom dataframe\n",
    "    df_med_info = x[\"medical_info\"].apply(pd.Series)\n",
    "    df_med_info = df_med_info.drop(0, 1)\n",
    "    x = pd.concat([x, df_med_info], axis = 1).drop(\"medical_info\", axis = 1)\n",
    "    return x\n",
    "\n",
    "def obj_to_float(df):\n",
    "    x = df.copy()\n",
    "    # kurtosis_oxygen\n",
    "    x['kurtosis_oxygen'] = x['kurtosis_oxygen'].astype(np.float)\n",
    "    # mean_oxygen\n",
    "    x['mean_oxygen'] = x['mean_oxygen'].astype(np.float)\n",
    "    # skewness_oxygen\n",
    "    x['skewness_oxygen'] = x['skewness_oxygen'].astype(np.float)\n",
    "    # std_oxygen\n",
    "    x['std_oxygen'] = x['std_oxygen'].astype(np.float)\n",
    "#     print(x.info())\n",
    "    return x\n",
    "\n",
    "def remove_unimportant_columns(df):\n",
    "    x = df.copy()\n",
    "    x = x.drop(['ID', 'name', 'fnlwgt', 'date_of_birth'], axis=1)\n",
    "    return x\n",
    "\n",
    "def remove_space(df):\n",
    "    x = df.copy()\n",
    "    x = df.apply(lambda y: y.str.strip() if y.dtype == \"object\" else y)\n",
    "    return x\n",
    "\n",
    "def put_0_1_values(df):\n",
    "    x = df.copy()\n",
    "    \n",
    "    # pohlavia: Male -> 1; Female -> 0\n",
    "    x['sex'] = x['sex'].replace('Male', 1)\n",
    "    x['sex'] = x['sex'].replace('Female', 0)\n",
    "    \n",
    "    # tehotnost: T -> 1; F -> 0\n",
    "    x['pregnant'] = x['pregnant'].replace(regex='(?i)f.*', value=0)\n",
    "    x['pregnant'] = x['pregnant'].replace(regex='(?i)t.*', value=1)\n",
    "    \n",
    "    # muzi oznaceni ako tehotny su prepisani na 0\n",
    "    x.loc[(x['pregnant'] == 1) & (x['sex'] == 1), 'pregnant'] = 0\n",
    "    \n",
    "    # zmena income hodnot: <=50K -> 0; >50K -> 1\n",
    "    x['income'] = x['income'].replace('<=50K', 0)\n",
    "    x['income'] = x['income'].replace('>50K', 1)\n",
    "    \n",
    "    # zmena nazvov stlpcov na presnejsie\n",
    "    x = x.rename(columns={\"pregnant\": \"is_pregnant\", \"income\": \"income_>50K\"})\n",
    "    \n",
    "    return x\n",
    "\n",
    "def education_analysis(df):\n",
    "    # prints unique values in education\n",
    "    x = df.copy()\n",
    "    unique_edu = pd.unique(x['education'])\n",
    "    print(\"Pred zjednotenim:\\n\", unique_edu)\n",
    "    \n",
    "    # Zjednotenie reprezentacii\n",
    "    x['education'] = x['education'].replace(regex='(?i)_', value='-')\n",
    "    unique_edu = pd.unique(x['education'])\n",
    "    print(\"\\nPo zjednoteni:\\n\", unique_edu)\n",
    "    \n",
    "    # hodnoty v education-num a v education\n",
    "    print(\"\\nHodnoty v jednotlivych education:\")\n",
    "    for item in unique_edu:\n",
    "        edu_num = x.query(\"education == @item\")[\"education-num\"].unique()\n",
    "        print(item, edu_num)\n",
    "        \n",
    "#vrati unikatne hodnoty v stlpci education\n",
    "def get_unique_edu(df):\n",
    "    x = df.copy()\n",
    "    x['education'] = x['education'].replace(regex='(?i)_', value='-')\n",
    "    unique_edu = pd.unique(x['education'])\n",
    "    return unique_edu\n",
    "\n",
    "# rozne hodnoty education-num pre unikatny education zmeni na jedno (napr.: 5th-6th [  3. 300.] -> 3)\n",
    "def get_edu_num(edu_num):\n",
    "    for num in edu_num:\n",
    "        if num is None:\n",
    "            continue\n",
    "        elif num < 100:\n",
    "            return int(num)\n",
    "\n",
    "def transform_education(df):\n",
    "    x = df.copy()\n",
    "    edu_to_num = {}\n",
    "    #vytvorenie dictionary s moznymi hodnotami v jendotlivych education values\n",
    "    for item in get_unique_edu(x):\n",
    "        edu_num = x.query(\"education == @item\")[\"education-num\"].unique()\n",
    "        edu_to_num[item] = get_edu_num(edu_num)\n",
    "    \n",
    "    # zmena moznych hodnot v education na rovnake\n",
    "    x['education'] = x['education'].replace(regex='(?i)_', value='-')\n",
    "\n",
    "    # namapuje nazvy education na cisla z dictionary\n",
    "    x[\"education\"] = x[\"education\"].map(edu_to_num)\n",
    "    \n",
    "    # Dropne nepotrebny column education-num (bol nahradeny)\n",
    "    x = x.drop(['education-num'], axis=1)\n",
    "    return x\n",
    "\n",
    "def find_state(address):\n",
    "    i = re.search('\\x5cn.+\\D', address)\n",
    "    return address[i.start():i.end()][-3:-1]\n",
    "    #return address[-8:][:2]\n",
    "\n",
    "def address_to_state(df):\n",
    "    x = df.copy()\n",
    "    x['address'] = x['address'].apply(find_state)\n",
    "    x = x.rename(columns={\"address\": \"state\"})\n",
    "    return x\n",
    "\n",
    "\n",
    "def replace_with_nan(df):\n",
    "    x = df.copy()\n",
    "    x = x.replace(['??', '?'], np.nan)\n",
    "    return x\n",
    "\n",
    "def transform_workclass(df):\n",
    "    x = df.copy()\n",
    "    x['workclass'] = x['workclass'].str.lower()\n",
    "    return x\n",
    "\n",
    "\n",
    "def integration_combined(df):\n",
    "    # merges other and personal df\n",
    "    df = merge_other_personal(df)\n",
    "    # upacks medical info into columns\n",
    "    df = unpack_medical(df)\n",
    "    # changes objects unpacked in medical info (odfygen) to float\n",
    "    df = obj_to_float(df)\n",
    "\n",
    "    # remove unimportant columns like name or fnlwgt\n",
    "    df = remove_unimportant_columns(df)\n",
    "    # removes spaces at the start of values\n",
    "    df = remove_space(df)\n",
    "    # replace values that have only 2 options vwith 1 or 2\n",
    "    df = put_0_1_values(df)\n",
    "    # gets rid of education and replaces it with number from education-num\n",
    "    df = transform_education(df)\n",
    "    # gets rid of address and only keep state\n",
    "    df = address_to_state(df)\n",
    "    # replaces ? with nan\n",
    "    df = replace_with_nan(df)\n",
    "    # workclass values into lower case -> gets rid of duplicates\n",
    "    df = transform_workclass(df)\n",
    "    return df\n",
    "\n",
    "def label_encode_strings(df):\n",
    "    \"\"\"Nahradi stringy ciselnymi hodnotami pomocou sklearn LabelEncoderu.\"\"\"\n",
    "    x = df.copy()\n",
    "    \n",
    "    enc = LabelEncoder()\n",
    "    cols_to_transform = ['race', 'state', 'marital-status', 'occupation', 'relationship', 'native-country', 'workclass']\n",
    "    x[cols_to_transform] = x[cols_to_transform].apply(enc.fit_transform)\n",
    "    \n",
    "    print(\"Table of mapping numeric values to cathegorical data:\\n\")\n",
    "    for i in cols_to_transform:\n",
    "        print(f'--- {i} ---')\n",
    "        values = df[i].unique()\n",
    "        encoded = enc.fit(values).transform(values)\n",
    "        encoding = enc.inverse_transform(encoded)\n",
    "        for e in range(len(encoded)):\n",
    "            print(f'{encoded[e]} : {encoding[e]}')\n",
    "        print('\\n')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def separate_by_dtype(df):\n",
    "    \"\"\"Rozdeli dataframe na stringy a numericke data.\"\"\"\n",
    "    df_num = pd.DataFrame()\n",
    "    df_str = pd.DataFrame()\n",
    "\n",
    "    for col in df:\n",
    "        # Ak je to int alebo float tak sa jedna o numericke data\n",
    "        if df[col].dtypes in ['float64', 'int64']:\n",
    "            df_num[col] = df[col]\n",
    "        else: # Inak string\n",
    "            df_str[col] = df[col]\n",
    "    \n",
    "    return df_num, df_str\n",
    "\n",
    "def replace_missing_strings(df):\n",
    "        \"\"\"Nahradi chybajuce stringy pomocou SimpleImputer zo sklearn.impute strategiou most_frequent.\"\"\"\n",
    "        x = df.copy()\n",
    "        x = SimpleImputer(strategy=\"most_frequent\").fit_transform(x)\n",
    "        \n",
    "        # Z novych hodnot sa vytvori dataframe\n",
    "        x = pd.DataFrame(x)\n",
    "        \n",
    "        # Pomenujeme stlpce a riadky rovnako ako v povodnom dataframe\n",
    "        x.columns = df.columns\n",
    "        x.index = df.index\n",
    "        \n",
    "        return x\n",
    "\n",
    "def replace_missing_numbers(df, strat='median'):\n",
    "    \"\"\"Nahradi chybajuce numericke data pomocou zvolenej strategie (median, mean alebo kNN).\"\"\"\n",
    "    x = df.copy()\n",
    "    \n",
    "    # Pre zvolenu strategiu sa vytvori imputer\n",
    "    if strat in ['mean', 'median']:\n",
    "        imp = SimpleImputer(strategy=strat)\n",
    "    else:\n",
    "        imp = KNNImputer()\n",
    "    \n",
    "    # Doplnia sa chybajuce hodnoty\n",
    "    x = imp.fit_transform(x)\n",
    "    \n",
    "    # Z novych hodnot sa vytvori dataframe\n",
    "    x = pd.DataFrame(x)\n",
    "    \n",
    "    # Pomenujeme stlpce a riadky rovnako ako v povodnom dataframe\n",
    "    x.columns = df.columns\n",
    "    x.index = df.index\n",
    "    \n",
    "    x['class'] = x['class'].round()\n",
    "    x['income_>50K'] = x['income_>50K'].round()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def replace_missing_values(df, strat='median'):\n",
    "    df_num, df_str = separate_by_dtype(df)\n",
    "    \n",
    "    df_str = replace_missing_strings(df_str)\n",
    "    df_num = replace_missing_numbers(df_num, strat)\n",
    "    \n",
    "    return pd.concat([df_str, df_num], axis=1, sort=False)\n",
    "\n",
    "def outliers(df, method='percentil'):\n",
    "    x = df.copy()\n",
    "    # vyber stlpcov pre ktore  chceme outlierov najst\n",
    "    outliners_for =['skewness_glucose','mean_glucose', 'std_glucose', 'kurtosis_glucose', \n",
    "                    'skewness_oxygen', 'mean_oxygen', 'std_oxygen', 'kurtosis_oxygen']\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column in outliners_for:\n",
    "            # vypocitame mean standard deviation pre stlpec\n",
    "            mean = x[column].mean()\n",
    "            std_dev = x[column].std()\n",
    "            # zistime hranicne hodnoty\n",
    "            border_right = mean + 3 * std_dev\n",
    "            border_left = mean - 3 * std_dev\n",
    "\n",
    "            # remove len ako test\n",
    "            if (method == 'remove'):\n",
    "                x.drop(x.loc[(x[column] > border_right)].index, inplace = True, axis=0)\n",
    "                x.drop(x.loc[(x[column] < border_left)].index, inplace = True, axis=0)\n",
    "            \n",
    "            # odstaranenie outlinerov pomocou percentilov\n",
    "            elif (method == 'percentil'):\n",
    "                #vypocet percentilov\n",
    "                p_95 = x[column].quantile(0.95)\n",
    "                p_05 = x[column].quantile(0.05)\n",
    "                # nahradenie hodnot za hranicami s percentilmi\n",
    "                x.loc[(x[column] > border_right), column] = p_95\n",
    "                x.loc[(x[column] < border_left), column] = p_05\n",
    "    \n",
    "    x = x.reset_index(drop=True)\n",
    "    return x\n",
    "\n",
    "def transform(df, method='power', plot='age'):\n",
    "    x = df.copy()\n",
    "    # vykreslenie grafu pred\n",
    "#     plt.figure()\n",
    "#     sns.histplot(x[plot], kde=True, color=\"Green\")\n",
    "    \n",
    "    # Power Transform\n",
    "    if method == 'power':\n",
    "        trans = PowerTransformer(method='yeo-johnson')\n",
    "    # Min Max Scale\n",
    "    else:\n",
    "        trans = MinMaxScaler()\n",
    "    \n",
    "    # aplikacia transformovania -> vrati array\n",
    "    x = trans.fit_transform(x)\n",
    "    # convert the array back to a dataframe -> columns mame zapisane ako ciselne hodnoty\n",
    "    dataset = pd.DataFrame(x)\n",
    "    # zmena ciselnych nazvov stlpcov v tabulke na slovne\n",
    "    X_imputed_df = pd.DataFrame(x, columns = df.columns)\n",
    "    # vykreslenie grafu po transformacii\n",
    "#     plt.figure()\n",
    "#     sns.histplot(X_imputed_df[plot], kde=True, color=\"Red\")\n",
    "    \n",
    "    return X_imputed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predspracovanie validačného datasetu realizovaným postupom predspracovania a opis prípadných zmien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of mapping numeric values to cathegorical data:\n",
      "\n",
      "--- race ---\n",
      "4 : White\n",
      "0 : Amer-Indian-Eskimo\n",
      "1 : Asian-Pac-Islander\n",
      "2 : Black\n",
      "3 : Other\n",
      "\n",
      "\n",
      "--- state ---\n",
      "38 : OH\n",
      "18 : IN\n",
      "8 : CO\n",
      "7 : CA\n",
      "48 : VA\n",
      "22 : MA\n",
      "13 : GA\n",
      "10 : DC\n",
      "2 : AK\n",
      "15 : IA\n",
      "46 : TX\n",
      "51 : WI\n",
      "42 : RI\n",
      "21 : LA\n",
      "37 : NY\n",
      "30 : NC\n",
      "34 : NJ\n",
      "0 : AA\n",
      "11 : DE\n",
      "52 : WV\n",
      "40 : OR\n",
      "3 : AL\n",
      "45 : TN\n",
      "20 : KY\n",
      "47 : UT\n",
      "41 : PA\n",
      "39 : OK\n",
      "4 : AP\n",
      "1 : AE\n",
      "53 : WY\n",
      "43 : SC\n",
      "25 : MI\n",
      "50 : WA\n",
      "26 : MN\n",
      "35 : NM\n",
      "49 : VT\n",
      "44 : SD\n",
      "6 : AZ\n",
      "27 : MO\n",
      "12 : FL\n",
      "14 : HI\n",
      "23 : MD\n",
      "9 : CT\n",
      "28 : MS\n",
      "19 : KS\n",
      "17 : IL\n",
      "31 : ND\n",
      "16 : ID\n",
      "32 : NE\n",
      "36 : NV\n",
      "5 : AR\n",
      "33 : NH\n",
      "29 : MT\n",
      "24 : ME\n",
      "\n",
      "\n",
      "--- marital-status ---\n",
      "4 : Never-married\n",
      "0 : Divorced\n",
      "2 : Married-civ-spouse\n",
      "5 : Separated\n",
      "3 : Married-spouse-absent\n",
      "6 : Widowed\n",
      "1 : Married-AF-spouse\n",
      "\n",
      "\n",
      "--- occupation ---\n",
      "7 : Other-service\n",
      "3 : Exec-managerial\n",
      "0 : Adm-clerical\n",
      "9 : Prof-specialty\n",
      "6 : Machine-op-inspct\n",
      "12 : Tech-support\n",
      "11 : Sales\n",
      "5 : Handlers-cleaners\n",
      "2 : Craft-repair\n",
      "13 : Transport-moving\n",
      "4 : Farming-fishing\n",
      "8 : Priv-house-serv\n",
      "10 : Protective-serv\n",
      "1 : Armed-Forces\n",
      "\n",
      "\n",
      "--- relationship ---\n",
      "1 : Not-in-family\n",
      "3 : Own-child\n",
      "0 : Husband\n",
      "5 : Wife\n",
      "4 : Unmarried\n",
      "2 : Other-relative\n",
      "\n",
      "\n",
      "--- native-country ---\n",
      "34 : United-States\n",
      "21 : Japan\n",
      "17 : India\n",
      "28 : Poland\n",
      "23 : Mexico\n",
      "8 : England\n",
      "2 : China\n",
      "27 : Philippines\n",
      "10 : Germany\n",
      "12 : Guatemala\n",
      "15 : Hong\n",
      "4 : Cuba\n",
      "3 : Columbia\n",
      "31 : South\n",
      "29 : Portugal\n",
      "30 : Puerto-Rico\n",
      "6 : Ecuador\n",
      "1 : Canada\n",
      "36 : Yugoslavia\n",
      "7 : El-Salvador\n",
      "20 : Jamaica\n",
      "24 : Nicaragua\n",
      "13 : Haiti\n",
      "5 : Dominican-Republic\n",
      "33 : Trinadad&Tobago\n",
      "9 : France\n",
      "19 : Italy\n",
      "35 : Vietnam\n",
      "18 : Iran\n",
      "11 : Greece\n",
      "14 : Honduras\n",
      "32 : Taiwan\n",
      "26 : Peru\n",
      "16 : Hungary\n",
      "0 : Cambodia\n",
      "22 : Laos\n",
      "25 : Outlying-US(Guam-USVI-etc)\n",
      "\n",
      "\n",
      "--- workclass ---\n",
      "3 : private\n",
      "0 : federal-gov\n",
      "4 : self-emp-inc\n",
      "1 : local-gov\n",
      "5 : self-emp-not-inc\n",
      "6 : state-gov\n",
      "7 : without-pay\n",
      "2 : never-worked\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3933 entries, 0 to 3932\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   state             3933 non-null   float64\n",
      " 1   race              3933 non-null   float64\n",
      " 2   marital-status    3933 non-null   float64\n",
      " 3   occupation        3933 non-null   float64\n",
      " 4   relationship      3933 non-null   float64\n",
      " 5   native-country    3933 non-null   float64\n",
      " 6   workclass         3933 non-null   float64\n",
      " 7   age               3933 non-null   float64\n",
      " 8   sex               3933 non-null   float64\n",
      " 9   is_pregnant       3933 non-null   float64\n",
      " 10  skewness_glucose  3933 non-null   float64\n",
      " 11  mean_glucose      3933 non-null   float64\n",
      " 12  capital-gain      3933 non-null   float64\n",
      " 13  kurtosis_glucose  3933 non-null   float64\n",
      " 14  education         3933 non-null   float64\n",
      " 15  class             3933 non-null   float64\n",
      " 16  std_glucose       3933 non-null   float64\n",
      " 17  income_>50K       3933 non-null   float64\n",
      " 18  hours-per-week    3933 non-null   float64\n",
      " 19  capital-loss      3933 non-null   float64\n",
      " 20  kurtosis_oxygen   3933 non-null   float64\n",
      " 21  mean_oxygen       3933 non-null   float64\n",
      " 22  skewness_oxygen   3933 non-null   float64\n",
      " 23  std_oxygen        3933 non-null   float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 737.6 KB\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('integration', FunctionTransformer(func=integration_combined)),\n",
    "    ('replace_nan', FunctionTransformer(func=replace_missing_values, kw_args={'strat': 'median'})),\n",
    "    ('to_numeric', FunctionTransformer(func=label_encode_strings)),\n",
    "    ('replace_outliers', FunctionTransformer(func=outliers, kw_args={'method': 'percentil'})),\n",
    "    ('transform', FunctionTransformer(func=transform, kw_args={'method': 'power', 'plot': 'std_glucose'}))\n",
    "])\n",
    "print\n",
    "df_t = pipeline.fit_transform(df)\n",
    "df_t.info()\n",
    "# df_v = pipeline.fit_transform(df)\n",
    "# df_v.info()\n",
    "#df.to_csv('after_preprocessing_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podľa tohto výpisu vidíme, že pipeline nám zbehla aj pre druhý  dataset. Nemali sme žiadne problémy a nič v pôvodnom kóde sme meniť nemuseli. Vidíme, že nemáme žiadne null v stĺpcoch a všetky hodnoty sú float64.  \n",
    "Môžeme vyhodnotiť, že predspracovanie prebehlo úspešne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
